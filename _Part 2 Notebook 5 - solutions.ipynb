{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Analytics - Exercises 5 solutions\n",
    "\n",
    "# Linear Classification\n",
    "\n",
    "## Objectives\n",
    "\n",
    "* To gain some practical experience with linear classification.\n",
    "* To reduce Bayesian classifiers to linear classifiers by constraining the covariances of the classes to be equal.\n",
    "* To compare the performance of a generative model and a discriminative model on a challenging classification task.\n",
    "\n",
    "## 1. Background\n",
    "\n",
    "In these exercises we will be revisiting the Bayesian classification code that we used in the previous exercises but we will constrain the system to have equal covariance matrices effectively turning it into a [linear classifier](https://en.wikipedia.org/wiki/Linear_classifier). We will then compare this 'generative’ approach with the 'discriminative’ approach: learning the linear classifier parameters directly by using the [perceptron](https://en.wikipedia.org/wiki/Perceptron) learning algorithm.\n",
    "\n",
    "## 2. Introduction\n",
    "\n",
    "In this notebook we will be using another data set from the UCI machine-learning repository: abalone data. An abalone is a type of sea snail. The age of a specimen can be determined by cutting the shell through the cone and counting rings through a microscope (rather like trees), but this is a time consuming and expensive procedure. The task here is to predict the number of rings given simple external measurements of the weight and dimension of the animal. For the data set we are using the real values are known (i.e. the rings were counted after the snails were measured). Results vary from 1 to 29 rings, so this would usually be treated as a 29-class classification problem. To simplify things a little I have regrouped the data into just two classes of roughly equal size: young (less than 10 rings) and old (10 or more rings). I have also only taken the female samples. There are 7 measurements (which are all quite highly correlated) that are to be used to predict the class label. (The precise meaning of the measurements can be found here http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names)\n",
    "\n",
    "Compared to the wine classification task this task is quite challenging. It will be impossible to get 100% correct because the classes are not [linearly separable](https://en.wikipedia.org/wiki/Linear_separability). Further, most of the specimens have either 8, 9, 10 or 11 rings and so lie close to the young/old borderline. However, you should be able to get percentage correct scores that are considerably higher than the 50% that would be expected by guessing alone.\n",
    "\n",
    "## 3. Obtaining the data\n",
    "\n",
    "The data can be read directly into a numpy array using the code in the cell below. The data will form a matrix with 1,306 rows and 8 columns. Each row is a separate sample (i.e. a different snail). The first column stores a class label (1 or 2). Columns 2 to 8 are the results of the 7 length and weight measurements. Note that, like in the last notebook, the features are stored as columns and the samples as rows. This makes things easier when using Python but the opposite convention is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.loadtxt(open(\"files/abalone.txt\",\"r\"))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generative modeling: Bayesian classification with equi-covariant multivariate normal distributions.\n",
    "\n",
    "Compared to last notebook, there are a lot more samples (1,306 compared with 178) so we will not worry about leave-one-out testing, instead, we will simply cut the data into equal sized testing and training sets like we did for the first half of the last notebook.\n",
    "\n",
    "By adapting the code you wrote last time, evaluate the performance of a Bayesian classifier using multivariate normal distributions with full covariance matrices. When considering changes to the code note that the main difference is that in this notebook there are only two classes rather than three. (If you wish you may trying wrapping the code into a function and seeing if you can design it so that it works for any number of classes.)\n",
    "\n",
    "How well does your classifier perform? (The score will probably be in the 60-70% range for this task, so don’t worry if performance seems a lot poorer than last notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "abalone1 = X[X[:,0]==1,:]\n",
    "abalone2 = X[X[:,0]==2,:]\n",
    "abalone1_test = abalone1[0::2,:]\n",
    "abalone1_train = abalone1[1::2, :]\n",
    "abalone2_test = abalone2[0::2,:]\n",
    "abalone2_train = abalone2[1::2, :]\n",
    "abalone_test = np.vstack((abalone1_test, abalone2_test))\n",
    "abalone_test.shape\n",
    "\n",
    "mean1 = np.mean(abalone1_train[:,1:], axis=0)\n",
    "mean2 = np.mean(abalone2_train[:,1:], axis=0)\n",
    "cov1 = np.cov(abalone1_train[:,1:], rowvar=0)\n",
    "cov2 = np.cov(abalone2_train[:,1:], rowvar=0)\n",
    "\n",
    "dist1 = multivariate_normal(mean=mean1, cov=cov1)\n",
    "dist2 = multivariate_normal(mean=mean2, cov=cov2)\n",
    "\n",
    "p1=dist1.pdf(abalone_test[:,1:])\n",
    "p2=dist2.pdf(abalone_test[:,1:])\n",
    "\n",
    "p = np.vstack((p1,p2))\n",
    "\n",
    "index = np.argmax(p, axis=0)+1\n",
    "\n",
    "plt.plot(index, 'k.', ms=10)\n",
    "\n",
    "correct = abalone_test[:,0]==index\n",
    "percent_correct = np.sum(correct)*100.0/index.shape\n",
    "print(percent_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using equal covariance matrices.**\n",
    "\n",
    "If you correctly followed the same procedures as last notebook you will have estimated a separate covariance matrix for each class. These matrices will not be equal and so the system will not have been a linear classifier. In order to reduce it down to a linear system we need to ensure that there is only one covariance matrix. There are different ways that you might imagine doing this:\n",
    "\n",
    "First, you might imagine simply estimating a single covariance matrix from the complete training set before dividing it into classes. This produces a single matrix but it is not the correct thing to do. We want the matrix to represent the spread *within* the classes, if you simply train a model using the full training data set it will also be capturing the spread *between* the classes.\n",
    "\n",
    "Second, you could imagine *averaging* the two class-dependent covariance matrices. This is closer to the correct thing but it doesn’t take care of the fact that the classes might have had unequal numbers of examples. The best approach is to first move the centres of the two classes onto the same point and then treat them as a single class. To move the class centres onto the same point you can simply subtract the class mean vector from each data sample.\n",
    "\n",
    "E.g., for each sample in class one you need to compute,\n",
    "    \n",
    "    abalone1_train(i,:)– mean1\n",
    "    \n",
    "and for each sample in class two you would compute,\n",
    "    \n",
    "    abalone2_train(i,:) – mean2\n",
    "\n",
    "You can do this without a loop. In fact you can just type\n",
    "  \n",
    "    abalone2_train - mean2\n",
    "  \n",
    "When numpy sees a vector being subtracted from a matrix like this, it will automatically copy the vector so that it is subtracted from every row of the matrix (this is called 'broadcasting').\n",
    "\n",
    "Go ahead and modify your code so that a single covariance matrix is computed called, for example, cov_global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "def centre_data(data):\n",
    "    nsamples = data.shape[0]\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    data_centred = data - data_mean\n",
    "    return data_centred\n",
    "\n",
    "abalone1_centred = centre_data(abalone1_train)\n",
    "abalone2_centred = centre_data(abalone2_train)\n",
    "\n",
    "abalone_centred = np.vstack((abalone1_centred, abalone2_centred))\n",
    "\n",
    "cov_global = np.cov(abalone_centred[:,1:], rowvar=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now redo the classification using this single matrix in both mvnpdf evaluations\n",
    "    \n",
    "    p1 = mvnpdf(abalone1_test, mean1, cov_global);\n",
    "    p2 = mvnpdf(abalone2_test, mean2, cov_global);\n",
    "    etc\n",
    "\n",
    "What is the new result? How does it compare with the result when using the more flexible non-linear classifer (i.e. when using two different covariance matrices)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist1 = multivariate_normal(mean=mean1, cov=cov_global)\n",
    "dist2 = multivariate_normal(mean=mean2, cov=cov_global)\n",
    "\n",
    "p1=dist1.pdf(abalone_test[:,1:])\n",
    "p2=dist2.pdf(abalone_test[:,1:])\n",
    "\n",
    "p = np.vstack((p1,p2))\n",
    "\n",
    "index = np.argmax(p, axis=0)+1\n",
    "\n",
    "plt.plot(index, 'k.', ms=10)\n",
    "\n",
    "correct = abalone_test[:,0]==index\n",
    "percent_correct = np.sum(correct)*100.0/index.shape\n",
    "print(percent_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wished we could represent this linear Gaussian classifier in the standard linear classifier form, i.e. $g(x) = w’x+w_0$ and output $\\omega_1$ if $g(x)>0$ else $\\omega_2$. The parameters $w’$ and $w_0$ would simply be a function of the covariance matrix and the class means that we have learnt from the training data. Actually, although this would involve an extra bit of calculation, once we had computed $w’$ and $w_0$, all the test points could be classified very quickly by evaluating $g(x)$ directly (e.g., for an $N$-dimension problem this amounts to just $N+1$ multiplications, $N$ additions and a comparison against 0).\n",
    "\n",
    "## 5. Disciminative modeling: the Perceptron learning algorithm ##\n",
    "\n",
    "In the 2nd half of this notebook we turn to look at a discriminative approach to classification in which the $w$ parameters needed for the evaluation of $g(x)$ are learnt directly. We will use the [perceptron learning algorithm](https://en.wikipedia.org/wiki/Perceptron); the pseudocode for this algorithm is roughly as follows:\n",
    "\n",
    "1. Initialize weights ${\\bf w}$ and thresholds\n",
    "2. For each example $i$ in the training set $X$, perform the following over the input ${\\bf x}_i$ and the class labels ${\\bf y}_i$:\n",
    "    1. Calculate the actual output $o_i(t) = f({\\bf w}(t) * {\\bf x}_i)$\n",
    "    2. Update the weights $w_i(t + 1) = w_i(t) - (y_i - o_i(t))x_{i,j}$ for all features $0 \\leq j \\leq \\mbox{n}$\n",
    "3. Repeat step (2) until the iteration error is smaller than a given error threshold (i.e. number of misclassifications is 'low enough'), or a pre-determined number of iterations were executed\n",
    "\n",
    "The perceptron learning algorithm is quite easy to implement, but in order to save time I’ve provided an implementation for you below. The function has several inputs: training data, training_labels, an initial guess at the weights and a learning rate. **Note, the class labels have to be given the values +1 and -1 for the two classes**. It will return a tuple containing:\n",
    "<ol>\n",
    "    <li>learnt w parameters</li>\n",
    "    <li>the number of iterations performed</li>\n",
    "    <li>the number of misclassfied samples</li>\n",
    "</ol>\n",
    "\n",
    "Take some time to examine the code. Don’t worry if it is not immediately clear how each line is working, but just satisfy yourself that you understand what each line is meant to be doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perce(X, y, w_init, rho):\n",
    "    \"\"\" perce\n",
    "    A simple but inefficient implementation of the perceptron learning alogorithm\n",
    "\n",
    "    X - the data matrix. Each row represents a separate sample\n",
    "    y - a vector of integer class labels corresponding to the rows of X - labels must be +1 or -1\n",
    "    w_init - the initial weight vector \n",
    "    rho - a scalar learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    (N, nfeatures) = X.shape\n",
    "    \n",
    "    # Augment the feature vectors by adding a 1 to each one. (see lecture notes)\n",
    "    X = np.hstack((X, np.ones((N,1))))\n",
    "    nfeatures += 1\n",
    "    \n",
    "    max_iter = 100  # maximum number of iterations\n",
    "    w = w_init      # initialise weights\n",
    "    iter = 0      \n",
    "    mis_class = N   # start by assuming all samples are misclassified\n",
    "\n",
    "    while mis_class > 0 and iter < max_iter:\n",
    "        iter += 1\n",
    "        mis_class = 0\n",
    "        gradient = np.zeros((1,nfeatures)) # initaliase the gradients to 0\n",
    "        \n",
    "        # loop over every training sample. \n",
    "        for i in range(N):\n",
    "            # each misclassified point will cause the gradient to change\n",
    "            if np.inner(X[i,:], w)*y[i] >= 0:\n",
    "                mis_class += 1\n",
    "                gradient += y[i] * X[i,:]\n",
    "        # update the weight vector ready for the next iteration        \n",
    "        w -= rho*gradient\n",
    "        \n",
    "    return w, iter, mis_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation above is quite straightforward. Unfortunately, the inner loop over the samples is very slow. This is largely because Python is an interpretted language. We can speed it up by processing all the points at the same time by using matrix operations than are processed by numpy. The improved implementation is shown below. Note how the inner loop has now 'vanished'. This version runs 100 times faster! Note that the max_iter has been set to 10000 rather than 100 so that up to 100 times as many iteraions may be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perce_fast(X, y, w_init, rho):\n",
    "    \"\"\" perce_fast\n",
    "    A more efficient implementation of the perceptron alogorithm\n",
    "    For the notebook data this version will work x100 faster!\n",
    "\n",
    "    X - the data matrix. Each row represents a separate sample\n",
    "    y - a vector of integer class labels corresponding to the rows of X - labels must be +1 or -1\n",
    "    w_init - the initial weight vector \n",
    "    rho - a scalar learning rate\n",
    "    \"\"\"\n",
    "    (N, nfeatures) = X.shape\n",
    "    X = np.hstack((X, np.ones((N,1))))\n",
    "    nfeatures += 1\n",
    "    max_iter = 10000\n",
    "    w = w_init\n",
    "    iter = 0\n",
    "    mis_class = N\n",
    "    yy = np.tile(y, (1, nfeatures))\n",
    "    while mis_class > 0 and iter < max_iter:\n",
    "        iter += 1\n",
    "        mis_class = 0\n",
    "        gradient = np.zeros((1,nfeatures))\n",
    "        mc = ((np.dot(X, w.transpose()) * y) >= 0)[:,0]\n",
    "        mis_class = np.sum(mc)\n",
    "        w -= rho * (np.sum(yy[mc, :] * X[mc, :], axis=0))\n",
    "    return w, iter, mis_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use perceptron function with the same training data that you used previously in order to learn the weights. You will need to read the documentation at the head of the function so that you understand what inputs are required. In particular, note that the class labels have to be in the form of a vector storing -1’s and +1’s. So you will have to manipulate your training data a little because it currently has the classes labeled represented as 1 and 2.\n",
    "\n",
    "Experiment with different learning rates and different numbers of iterations. The function returns the number of errors that are made on the training set. You want this number to be as low as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "abalone_train = np.vstack((abalone1_train, abalone2_train))\n",
    "abalone_train_data = abalone_train[:, 1:]\n",
    "abalone_train_labels = np.array([abalone_train[:, 0]]).transpose() * 2 - 3\n",
    "\n",
    "#rho = 1\n",
    "#w_init = np.zeros((1, abalone_train_data.shape[1]+1))\n",
    "#w, iter, mis_class = perce(abalone_train_data, abalone_train_labels, w_init, rho)\n",
    "#print(w)\n",
    "#print(mis_class)\n",
    "\n",
    "rho = 0.1\n",
    "w_init = np.zeros((1, abalone_train_data.shape[1]+1))\n",
    "w, iter, mis_class = perce_fast(abalone_train_data, abalone_train_labels, w_init, rho)\n",
    "print(w)\n",
    "print(mis_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the classifier:** You now need to evaluate the $w$ vector that the learning algorithm has produced. To do this you will need to evaluate $w’x+w_0$ for each element in the test set and generate a label by comparing the result against 0. Then compute the percentage of labels that match the correct test set labels. It is probably best to write a little function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Make test data and test labels\n",
    "abalone_test = np.vstack((abalone1_test, abalone2_test))\n",
    "abalone_test_data = abalone_test[:, 1:]\n",
    "abalone_test_labels = np.array([abalone_test[:, 0]]).transpose() * 2 - 3\n",
    "\n",
    "# Perform classification - copied from perce_fast\n",
    "X = abalone_test_data\n",
    "(N, nfeatures) = X.shape\n",
    "X = np.hstack((X, np.ones((N,1))))\n",
    "mc = ((np.dot(X, w.transpose()) * abalone_test_labels) >= 0)[:,0]\n",
    "mis_class = np.sum(mc)\n",
    "\n",
    "# Convert number of miss classifications into percentage correct\n",
    "print (100.0 - mis_class*100.0/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the new classifier perform? How does performance compare with the linear classifier that you built using Gaussians in the first half of the notebook?\n",
    "\n",
    "## 6. Notes\n",
    "\n",
    "You should find that although the new classifier is again linear, its performance is a little better. You might be confused about this because it is said that Bayesian classifiers are optimal – their decision boundaries are positioned so as to minimize the number of classification errors. However, this is only true in the theoretical sense that they are optimal if we use the correct distribution for $p(x|w)$. In practice we don’t know this distribution so we estimate it from the training data. This is typically done by assuming $p(x|w)$ has some general shape (e.g. Gaussian) and then estimating specific parameters, e.g. means and covariances, that best fits the training data. This would be fine is our initial assumption was correct, but the fact is that the data is very unlikely to fit some nice well-behaved distribution like a Gaussian. For example, it might be approximately Gaussian but slightly skewed, or with slightly elongated tails etc etc. So even with the best possible parameter tuning there will still exist a discrepancy between the $p(x|w)$ that we’ve estimated and the true distribution. If we aren’t using the correct $p(x|w)$ then all bets are off and we can’t guarantee that the model we have chosen will be the one that minimizes errors.\n",
    "\n",
    "The discriminative approach on the other hand is doing something that is closer to directly minimizing errors. It is doing this without regard to the distribution of $p(x|w)$. This more pragmatic approach often works better particularly in cases where $p(x|w)$ has a complicated distribution that is hard to parameterize. It is also perhaps closer to what we do as humans, e.g. we are often not aware of small differences within classes (e.g. in speech, all ‘b’ phonemes sound roughly similar) but we are very sensitive to small changes at the borders between classes (‘b’ and ‘p’ are perceptually quite different, but if you look at features extracted from their sound signals they can be extremely similar).\n",
    "\n",
    "# Programming Challenge\n",
    "\n",
    "## 7. Programming exercise\n",
    "\n",
    "Two versions of the Perceptron learning algorithm are discussed. The first works in batch mode like the code you have used here, i.e. all points are first classified and then the weights are updated. The second, works in an online mode and processes the samples one at a time, i.e. the w parameters are adjusted directly after processing each sample.\n",
    "\n",
    "Copy the function perce() into the cell below and then rewrite it so that it works in the online manner. (Note, unfortunately, the fast version perce_fast cannot be made to run in an online manner because it gets its speed precisely because it processes all samples in one step.) Does it produces better results for the Abalone task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
