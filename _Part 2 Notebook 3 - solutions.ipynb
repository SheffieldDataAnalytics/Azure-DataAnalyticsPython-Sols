{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Data Analytics - Exercises 3 solutions #\n",
    "\n",
    "# Computing Expectations by using Numerical Integration #\n",
    "\n",
    "## Objectives ##\n",
    "\n",
    "* To gain experience with some more advanced Python programming features: passing functions as parameters; defining 'anonymous’ functions.\n",
    "* To see how numerical integration can be used to approximate the [mean](https://en.wikipedia.org/wiki/Mean) and [variance](https://en.wikipedia.org/wiki/Variance) of a distribution.\n",
    "\n",
    "## 1. Background ##\n",
    "\n",
    "Expectations of continuous random variables (e.g. means and variances) can be computed from the probability density function by integration. ‘Analytic’ integration can be used to derive exact expressions for the mean and variance of the Gaussian distribution and the uniform distribution. Sometimes integration can be hard to perform analytically. In such cases it is possible to resort to approximate numerical techniques to compute the mean and variance. There are two main approaches that can take:\n",
    "<ol>\n",
    "    <li>[monte-carlo sampling](https://en.wikipedia.org/wiki/Monte_Carlo_method): (i.e. generating samples from the distribution and computing their statistics directly)</li>\n",
    "    <li>integration by [numerical quadrature](https://en.wikipedia.org/wiki/Numerical_integration), (i.e. approximating the area under a curve by cutting it into a finite number of slithers that we then sum up).</li>\n",
    "</ol>\n",
    "\n",
    "Quadrature works very well for 1-D problem and this will be the focus of this notebook.\n",
    "\n",
    "# PART 1 – Numerical quadrature #\n",
    "\n",
    "## 2. Introduction ##\n",
    "\n",
    "Numerical quadrature is a form of numerical integration and can be used to integrate functions between definite limits, i.e. finding the area under a curve between a lower and upper limit on the x-axis. There are several different versions of the technique but they all work in the same way. The area under the curve is approximated by summing a series of segments whose area is easy to compute. In the simplest case the segments are very thin rectangles and the area under the curve can be approximated by summing the area of each of the rectangles shown. Note that the width of each rectangle is some fixed step size, and the heights are calculated by evaluating the function f(x) at the x position where the rectangle is centered. The area of each is simply the width times the height.\n",
    "\n",
    "The more rectangles we use, the thinner they will be and the closer the sum of their areas will be to the true area under the curve. i.e. by summing more rectangles we can improve the precision of the approximation – at the expense of additional computational effort.\n",
    "\n",
    "## 3. Passing function as arguments ##\n",
    "\n",
    "Python already has functions for performing numeric integration but in order to get some more Python programing experience you are going to write your own. Your function needs to take four inputs:\n",
    "\n",
    "* f() - the function we wish to integrate,\n",
    "* a - the lower bound,\n",
    "* b - the upper bound and\n",
    "* N - the number of segments to be used to approximate the integral.\n",
    "\n",
    "Note, the 1st parameter is a function – we are passing a function to a function. In Python it is possible to pass functions directly. Let’s illustrate this by passing the math.cos() function as a parameter to a function called squared that can compute the squared output of any function:\n",
    "First write the function squared like this\n",
    "\n",
    "    function y=squared(fn, x)\n",
    "    y = fn(x);\n",
    "    y=y.^2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def squared(fn, x):\n",
    "    y = fn(x)\n",
    "    y = y * y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now to compute the square of cos(pi/3) we could call our function as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "squared(np.cos, np.pi/3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now if we wanted to compute the square of sin(pi/2) we could simply write,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "squared(np.sin, np.pi/3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What happens if you try the following,\n",
    "\n",
    "    squared(np.sin, np.linspace(0,2*np.pi,100))\n",
    "    \n",
    "Try it in the cell below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "squared(np.sin, np.linspace(0,2*np.pi,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The above example works because np.sin() has been designed to be able to take a vector of inputs and compute the sin of every element in the vector. All the numpy functions will work in this way. This makes the numpy library very fast and powerful.\n",
    "\n",
    "## 4. Numerical integration ##\n",
    "\n",
    "We now need to write our numerical integration function.\n",
    "\n",
    "Say we want to integrate $f()$ between $a$ and $b$. We are first going to evaluate $f(x)$ at lots of\n",
    "positions between $a$ and $b$, (say $N$ positions).\n",
    "\n",
    "To do this we can first generate a number line with $N$ points between a and b stored in the vector\n",
    "x. We can do this using numpy's [linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) function x = np.linspace(a, b, N)\n",
    "\n",
    "We then pass the vector $x$ to our function $f()$ in the usual way.\n",
    "\n",
    "    fx = f(x)\n",
    "\n",
    "This gives us the heights of the rectangles on the previous page. There will be $N$ rectangles between $a$ and $b$ so we can work out that their width will be $(b-a)/N$. So the area of each one is $fx(i) . (b-a)/N$. So our integral, which is the total area of all the rectangles combined, is given by\n",
    "\n",
    "    np.sum(fx)*(b-a)/N\n",
    "\n",
    "The more slithers we use the better the accuracy will be.\n",
    "The function signature for our integrate function should look like\n",
    "\n",
    "    integrate(f, a, b, N)\n",
    "    \n",
    "Putting this all together we have the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def integrate(f, a, b, N):\n",
    "    x = np.linspace(a, b, N)\n",
    "    fx = f(x)\n",
    "    area = np.sum(fx)*(b-a)/N\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can now use the function to integrate a sine curve between 0 and and pi/2. This should produce 1. Let's run it using 100 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "integrate(np.sin, 0, np.pi/2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The answer is off by about 0.002. This is not bad. In fact the integrate function above is simple but it is not *quite* right. If you consider the points generated by linspace then you might be able to spot the error. Try fixing it in rerunning the test. If you get it right the error will be about 200 times smaller (Rewrite the integrate function in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def integrate(f, a, b, N):\n",
    "    x = np.linspace(a+(b-a)/(2*N), b-(b-a)/(2*N), N)\n",
    "    fx = f(x)\n",
    "    area = np.sum(fx)*(b-a)/N\n",
    "    return area\n",
    "\n",
    "integrate(np.cos, 0, np.pi/2, 100) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 5. Computing the mean of a distribution ##\n",
    "\n",
    "Remember, if x is a random variable with distribution p(x) then its mean value, E(x) is given by integrating x.p(x) between plus and minus infinity.\n",
    "\n",
    "We will now make a new function called compute_mean that takes the distribution as an input function. The compute_mean will also take the upper and lower bounds and N slices parameters that will be passed on to the integrate function. So define a new function with the following signature,\n",
    "\n",
    "    function m = compute_mean(f, a, b, N)\n",
    "\n",
    "Inside the body of this function we will use our function integrate to evaluate the integral of x.f(x).\n",
    "\n",
    "But how can we pass x.f(x) to integrate? integrate() takes the function that we want to integrate as input, but the problem is that we haven’t written a function that directly evaluates x.f(x).\n",
    "\n",
    "The solution is to use a Python inner function to define a new function inside the compute_mean function body.\n",
    "\n",
    "\n",
    "`compute_mean` has been passed a function called f and we want to write a new function that evaluates x.f(x). Elementwise multiplication of two vectors can be done using numpy's multiply() function. So our inner-function will look like \n",
    "\n",
    "    def xfx(x):\n",
    "        return np.multiply(f(x), x)\n",
    "        \n",
    "Note that f2() did not need to be passed the function f() as it inherited from the scope of the containing function compute_mean()    \n",
    "\n",
    "Once this function has been defined we can now integrate it using our integrate function and so compute the mean, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mean(f, a, b, N):\n",
    "    def xfx(x):\n",
    "        return np.multiply(x, f(x))\n",
    "    mean = integrate(xfx, a, b, N)\n",
    "    return mean\n",
    "\n",
    "compute_mean(np.cos, 0, np.pi/2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 6. Testing the compute_mean function ##\n",
    "\n",
    "We can now test our compute mean function. The Python scipy.stats package has functions to handle many distributions. To get a function that evaluates the [pdf](https://en.wikipedia.org/wiki/Probability_density_function) of a [Gaussian](https://en.wikipedia.org/wiki/Normal_distribution) we first generate a randon variable using\n",
    "\n",
    "     x = norm(0, 1)\n",
    "\n",
    "and then we can call\n",
    "\n",
    "    x.pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "x = norm(0, 1)\n",
    "compute_mean(x.pdf, -5, 5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Experiment with different a, b and N parameters and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Average of f(x) for x positive\n",
    "print (compute_mean(x.pdf, 0, 100, 1000))\n",
    "# Average for x positive - less accurate\n",
    "print (compute_mean(x.pdf, 0, 100, 100))\n",
    "# Average for x positive - even less accurate\n",
    "print (compute_mean(x.pdf, 0, 100, 10))\n",
    "# Average f(x) for x in range 2 to 3\n",
    "print (compute_mean(x.pdf, 2, 3, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To evaluate a normal pdf with mean 5 and variance 4 we simply need to call the norm function with different mean and standard deviation parameters\n",
    "\n",
    "    x = norm(5, 2)\n",
    "    \n",
    "Experiment with different values of the mean and check that the mean estimation still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Estimate mean of normal with mean = 5, var = 4\n",
    "print (compute_mean(norm(5,2).pdf, -10, 10, 1000))\n",
    "# Estimate mean of normal with mean = 2, var = 9\n",
    "print (compute_mean(norm(2,3).pdf, -10, 10, 1000))\n",
    "# Estimate mean of normal with mean = -2, var = 1\n",
    "print (compute_mean(norm(-2,1).pdf, -10, 10, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(Note, the 3rd parameter sets the standard deviation – the square root of variance – so for a variance of 4 we need to set the standard deviation to 2).\n",
    "\n",
    "We can compute the mean of the uniform pdf using similar code,\n",
    "\n",
    "    from scipy.stats import uniform\n",
    "    x = uniform(0, 1)\n",
    "    \n",
    "The two parameters are now the range of the uniform variable. i.e. x is uniform between 0 and 1.\n",
    "\n",
    "Try estimating the mean for various different uniform distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "from scipy.stats import uniform\n",
    "# For uniform distribution the mean should be 0.5(a+b)\n",
    "print (compute_mean(uniform(1,3).pdf, -10, 10, 100))\n",
    "print (compute_mean(uniform(-2,3).pdf, -10, 10, 100))\n",
    "print (compute_mean(uniform(3,8).pdf, -10, 10, 1000))# why is this one so far off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 7. Computing the variance ##\n",
    "\n",
    "We will now extend compute_mean so that it also computes the variance. Make a new function called `compute_mean_and_variance` with the same parameters as `compute_mean` but which returns both a mean and a variance\n",
    "\n",
    "    compute_mean_and_variance(f, a, b, N) \n",
    "\n",
    "Copy the code from `compute_mean` so that the mean computation is complete.\n",
    "\n",
    "Variance is E((x-E(x))^2). This can be rearranged into a handier form as var(x) = E(x^2) – E(x)^2.\n",
    "\n",
    "Our function already computes E(x) i.e. the mean. We now just need to extend it to compute E(x^2). i.e. we need to integrate x^2.p(x) . Do this using the same steps described in section 3. i.e. you will need to define another anonymous function in the `compute_mean_and_variance` function body to evaluate x^2.p(x) and then pass this to the integrate function to compute E(x^2). Once you have evaluated E(x) and E(x^2) you can use them to compute var(x).\n",
    "\n",
    "Write your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def compute_mean(f, a, b, N):\n",
    "    def xfx(x):\n",
    "        return np.multiply(x, f(x))\n",
    "    mean = integrate(xfx, a, b, N)\n",
    "    return mean\n",
    "\n",
    "def compute_mean_and_var(f, a, b, N):\n",
    "    def xfx(x):\n",
    "        return np.multiply(x, f(x))\n",
    "    mean = integrate(xfx, a, b, N)\n",
    "    def xxfx(x):\n",
    "        return np.multiply(np.multiply(x, x), f(x))\n",
    "    meanxx = integrate(xxfx, a, b, N)\n",
    "    var = meanxx - mean*mean\n",
    "    return mean, var\n",
    "\n",
    "x = norm(1,2)\n",
    "compute_mean_and_var(x.pdf, -15, 15, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 8. Evaluating the estimates ##\n",
    "\n",
    "Generate a normal random variable with mean 5 and variance 4  (i.e. x = norm(5,2))\n",
    "\n",
    "Set the limits of the integration to be -100 to 100. Now call `compute_mean_and_variance`\n",
    "with increasing values of N.\n",
    "\n",
    "Given that in this case we know the true mean and variance (i.e. 5 and 4) we can compute the\n",
    "error in the estimates (i.e. the difference between the estimates and the true values). \n",
    "\n",
    "Make a plot of the estimation error as a function of N.\n",
    "\n",
    "How quickly does the error decrease with increasing N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# Make the distribution\n",
    "mean_true = 5\n",
    "var_true = 4\n",
    "x = norm(mean_true, math.sqrt(var_true))\n",
    "\n",
    "# Some values of N to try\n",
    "Ns = [2, 5, 10, 19, 20, 21, 30, 40, 50,60,70,80,90,100]\n",
    "\n",
    "# Storage for the results\n",
    "mean_error = np.empty(len(Ns))\n",
    "var_error = np.empty(len(Ns))\n",
    "\n",
    "# Compute estimation errors for different value of N\n",
    "for index, N in enumerate(Ns):\n",
    "    mean_est, var_est = compute_mean_and_var(x.pdf, -100.0, 100.0, N)\n",
    "    mean_error[index] = mean_true - mean_est\n",
    "    var_error[index] = var_true - var_est\n",
    "\n",
    "# Plot - note error generally descreases for increasing N \n",
    "# ... but strange behaviour at N = 20. Why is this?\n",
    "ax=plt.subplot(1,2,1)\n",
    "ax.plot(Ns, mean_error);\n",
    "ax=plt.subplot(1,2,2)\n",
    "ax.plot(Ns, var_error);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9. Challenge: Using your code ##\n",
    "\n",
    "A variable x has a pdf defined by $p(x)=30*x*(1-x)^4$ for $x>=0$ and $x<=1$\n",
    "and $p(x) = 0$ for $x<=0$ and $x>=1$.\n",
    "\n",
    "Use your code to compute the mean and variance of this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def f(x):\n",
    "    return 30.0 * np.multiply(x, np.power(1.0-x, 4))\n",
    "\n",
    "mean_est, var_est = compute_mean_and_var(f, 0.0, 1.0, 100)\n",
    "print(mean_est)\n",
    "print(var_est)\n",
    "\n",
    "# This is actually a distribution from the Beta distribution family\n",
    "# This one is Beta(2,5) and the true mean and variance should be\n",
    "print (2.0/(2.0+5.0))\n",
    "print ((2.0*5.0)/((2.0+5.0)*(2.0+5.0)*(2.0+5.0+1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PART 2 – Programming Challenge #\n",
    "\n",
    "Bayesian inference assumes that the probability of each attribute belonging to a given class value is independent of all other attributes. Conditional probability is the probability of a class value given a value of an attribute; by multiplying the conditional probabilities together for each attribute for a given class value, we have a probability of a data instance belonging to that class. This is also represented by the frequently seen formula\n",
    "\n",
    "$$P(A|B) = \\frac{P(B | A) P(A)}{P(B)}$$\n",
    "\n",
    "where\n",
    "\n",
    "* P(A|B) is the posterior probability of class (A) given predictor (B)\n",
    "* P(A) is the prior probability of class\n",
    "* P(B|A) is the likelihood\n",
    "* P(B) is the prior probability of predictor\n",
    "\n",
    "## 10. Programming exercise ##\n",
    "\n",
    "#### Exercise 1. #### \n",
    "\n",
    "Simulate tossing a fair coin 1,000,000 times. Count the length of each sequence of identical outcomes. Plot a histogram of the result.\n",
    "\n",
    "For example, the following sequence, H H H T T H H H H T T T, would count as 1 sequence of 2 (T T); 2 sequences of 3 (H H H and T T T) and 1 sequence of 4 (H H H H).\n",
    "\n",
    "Hint: the coin toss can be simulated by using the function 'rand’ to pick a number between 0 and 1 and outputting heads if the number is greater than 0.5 or else outputting tails.\n",
    "Write your solution using a for-loop to start with.\n",
    "\n",
    "Can you find a way of 'vectorising’ your algorithm – i.e. writing it without loops? Is it faster?\n",
    "    \n",
    "Time your solutions using timeit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def do_tosses(ntosses):\n",
    "    outcomes = np.random.rand(ntosses)>0.5\n",
    "    sequence_length=1\n",
    "    sequence_lengths = []\n",
    "    last_outcome = outcomes[0]\n",
    "    for outcome in outcomes[1:]:\n",
    "        if outcome != last_outcome:\n",
    "            sequence_lengths.append(sequence_length)\n",
    "            sequence_length = 1\n",
    "        else:\n",
    "            sequence_length+=1\n",
    "        last_outcome = outcome\n",
    "    sequence_lengths.append(sequence_length)\n",
    "    return sequence_lengths\n",
    "\n",
    "%timeit do_tosses(1000000)\n",
    "\n",
    "sequence_lengths = do_tosses(1000000)\n",
    "x = plt.hist(sequence_lengths, bins=np.linspace(0,10,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def do_tosses2(ntosses):\n",
    "    # I'll leave adding comments as an exercise...\n",
    "    outcomes = np.random.rand(ntosses)>0.5\n",
    "    changes = outcomes[1:] != outcomes[:-1]\n",
    "    changes = np.insert(changes, 0, True)\n",
    "    changes = np.append(changes, True)\n",
    "    change_positions = np.where(changes==True)\n",
    "    sequence_lengths = np.diff(change_positions)\n",
    "    return sequence_lengths.T\n",
    "    \n",
    "%timeit do_tosses2(1000000)\n",
    "\n",
    "sequence_lengths = do_tosses2(1000000)\n",
    "x = plt.hist(sequence_lengths, bins=np.linspace(0,10,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Exercise 2. ####\n",
    "\n",
    "Bias the coin so that it comes up heads with a probability, p, greater than 0.5. How does the shape of the histogram vary with increasing p?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "def do_biased_tosses(bias, ntosses):\n",
    "    # I'll leave adding comments as an exercise...\n",
    "    outcomes = np.random.rand(ntosses)>bias\n",
    "    changes = outcomes[1:] != outcomes[:-1]\n",
    "    changes = np.insert(changes, 0, True)\n",
    "    changes = np.append(changes, True)\n",
    "    change_positions = np.where(changes==True)\n",
    "    sequence_lengths = np.diff(change_positions)\n",
    "    return sequence_lengths.T\n",
    "    \n",
    "# biased coin produces relatively more long unchanging sequences \n",
    "sequence_lengths = do_biased_tosses(0.7, 1000000)\n",
    "x = plt.hist(sequence_lengths, bins=np.linspace(0,10,11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
