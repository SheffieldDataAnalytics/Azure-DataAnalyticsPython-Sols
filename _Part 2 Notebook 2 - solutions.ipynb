{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Data Analytics - Exercises 2 solutions #\n",
    "\n",
    "# Writing Python functions – Understanding Sampling #\n",
    "\n",
    "## Objectives ##\n",
    "\n",
    "* To gain an intuitive understanding of sample statistics.\n",
    "\n",
    "## 1. Background\n",
    "\n",
    "In this notebook class you’ll be using data that represents the weights and lengths of male and female **Bengal tigers**. In order to build classifiers we are going to want to be able to estimate the [means](https://en.wikipedia.org/wiki/Mean) (i.e. averages), [variances](https://en.wikipedia.org/wiki/Variance) and [covariance](https://en.wikipedia.org/wiki/Covariance) of these measurements. In order to discover the true means and variances we’d have to catch and measure every one of the roughly 2,500 tigers that are thought to exist – a project that is clearly impractical. So, instead we will have to be satisfied with an **estimate** of the true mean and variance that we generate by looking at the statistics of a small **sample** of tigers (e.g. we might catch and measure 20 animals). This is generally always going to be the case: we will be interested in the statistics of a large population, but we will have to make do with estimates derived from a smaller – often much smaller – sample.\n",
    "\n",
    "**In Part 1 of this notebook** we will be using Python to find out what happens when we try to compute estimates of statistics using small samples. We will see how the reliability of the estimates improves as the sample size increases. We will also see how estimates of variance and covariance can be biased (i.e. systematically too small or too large) if we don’t handle the sample correctly.\n",
    "\n",
    "**Part 2 consists of some little Python programming challenges.** \n",
    "\n",
    "# PART 1 – Sample Statistics\n",
    "\n",
    "## 2. Loading and understanding the data\n",
    "\n",
    "The tiger population data we are using has been made up (i.e. no-one really knows the weights and lengths of every living Bengal tiger) but it has been generated to be consistent with the ranges of weight and length that are quoted on Wikipedia. It has also been engineered so that the population statistics are nice round numbers, i.e. just to make things a little clearer.\n",
    "\n",
    "(**Remember, to execute a cell, first click on it so that it is in focus and then click the run button in the tool bar, or ctrl-enter**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "female_tigers = np.loadtxt(open(\"files/female_tigers.txt\",\"rb\"))\n",
    "male_tigers = np.loadtxt(open(\"files/male_tigers.txt\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You will now have two matrices each with 1,250 columns and two rows. The columns represent the tigers (1,250 of each gender). The first row gives the weight (in kg) and the second the length (in cm).     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(female_tigers.shape)\n",
    "print(female_tigers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We have access to the data for all the tigers so we can compute the true mean and variance of the weight and length features. For example, for the female tigers try,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(female_tigers, axis=1))\n",
    "print(np.var(female_tigers, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We are now going to imagine that we don’t know this truth but need to estimate it from a small sample of tigers that have been caught, weighed and measured.\n",
    "\n",
    "## 3. Sampling the data\n",
    "\n",
    "Imagine that you have gone out and caught 20 female tigers and measured them. You’d now know the measurements of 20 tigers of the 1250 that exist. Let’s simulate this experiment by taking the first 20 of the female tigers from our complete population data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sample = female_tigers[:, 1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let’s compute the mean and variance of both the length and weight features in our sample,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(sample, axis=1))\n",
    "print(np.var(sample, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notice how these estimates are not the same as the true mean and variance. But how close to the real values are they likely to be?\n",
    "\n",
    "## 4. Repeated sampling\n",
    "\n",
    "If we repeated our experiment and caught 20 different tigers we would get a different set of measurement and hence a different estimate of the mean and variance. Using Python we can simulate running this experiment 1000’s of times and getting 1000’s of different estimates of the mean and variance. We can then plot a histogram of these estimates and compare them to the true values (which we wouldn’t know in reality but which we computed above by using all the data).\n",
    "\n",
    "So we will now repeat the experiment. In order to catch 20 different tigers we use the random.choice function in Python's numpy library. This function can return randomly chosen integers between 0 and some maximum value. It can be instructed to select them 'without replacement' i.e. so that the same number cannot be chosen twice. We will use this to make an array of random indices amd then use this array to select random columns from the female_tiger data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "chosen = np.random.choice(female_tigers.shape[1], 20, replace=False)\n",
    "sample = female_tigers[:, chosen]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, compute the sample mean and variance for the tiger weights again and see that the result has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(sample[1,:]))\n",
    "print(np.var(sample[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Run the above two cells over and over again. Note how each time you get a different mean and variance estimate.\n",
    "\n",
    "## 5. Writing a sampling function\n",
    "\n",
    "We are now going to wrap our sampling and mean and variance calculations into an easily reusable function.\n",
    "\n",
    "The function’s inputs should be the complete population data and the sample size; the output should be the mean and variance estimates, i.e. the first line of the function should look like this,\n",
    "\n",
    "    def calc_sample_stats(data, N)\n",
    " \n",
    "and the return will be\n",
    "         \n",
    "    return mean_estimate, var_estimate\n",
    "\n",
    "The full code is below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calc_sample_stats(data, N):\n",
    "    chosen = np.random.choice(data.shape[1], N, replace=False)\n",
    "    sample = data[:, chosen]\n",
    "    mean_estimate = np.mean(sample, axis=1)\n",
    "    var_estimate = np.var(sample, axis=1)\n",
    "    return mean_estimate, var_estimate\n",
    "\n",
    "print(calc_sample_stats(female_tigers, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Test the function the using different values of N in the cell below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "print(calc_sample_stats(female_tigers, 5))\n",
    "print(calc_sample_stats(female_tigers, 30))\n",
    "print(calc_sample_stats(female_tigers, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now we will write another function called do_sampling. This script is going to call your calc_sample_stats function lots of times by using a loop. It will save the results of each run in a python array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def do_sampling(data, sample_size, n_repeats):\n",
    "    sample_means = np.zeros((2,n_repeats))\n",
    "    sample_vars = np.zeros((2,n_repeats))\n",
    "    for i in range(n_repeats): \n",
    "        sample_means[:,i],sample_vars[:,i]=calc_sample_stats(female_tigers, sample_size)\n",
    "    return sample_means, sample_vars\n",
    "\n",
    "sample_means, sample_vars = do_sampling(female_tigers, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can now plot a histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sample_means, sample_vars = do_sampling(female_tigers, 10, 10000)\n",
    "plt.hist(sample_means[0,:], 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "or    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(sample_means[1,:], 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How does the distribution of the sample means compare with the true mean value?\n",
    "\n",
    "To make a histogram of the variance estimates,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(sample_vars[0,:], 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(sample_vars[1,:], 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How does the distribution of the sample variance compare with the true variance?\n",
    "\n",
    "Calculate the average of the mean estimates, i.e. mean(sample_mean). Are the estimates (on average) the same as the true mean value? Do the same for the variance estimates. Are the variance estimates on average the same as the true variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(np.mean(sample_vars, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 6. Notes on bias\n",
    "\n",
    "You should have noticed in the previous section that the variance estimates were on average lower than the true variance. The estimate is biased. You can correct for this bias by multiplying by N/N-1 or, alternatively, by dividing by N-1 instead of N when you do the original variance calculation. \n",
    "\n",
    "(Why does the sample variance under-estimate the true variance? Informal explanation: The point to remember is that the variance is the average squared distance of points from the true mean. When we take our sample we form an estimate of the mean. So when we estimate variance we are computing the distance of points to the estimated mean not the true mean. The estimated mean is going to be at the centre of our sample and will always be closer to the sample points than the true mean. This is seen clearly by taking the extreme case of a sample size of 1. For a single point the sample mean will always be the sample itself, i.e. the distance to the sample mean is 0 so the sample variance is 0 --- which is clearly a severe underestimate of the true variance. )\n",
    "\n",
    "## 7. Experimenting with the sample size\n",
    "\n",
    "Now let’s experiment with different sample sizes and see how changing the sample size changes the distribution of the estimates of mean and variance.\n",
    "\n",
    "We will use sample sizes of 2, 5, 10, 20, 40 and 100.\n",
    "\n",
    "Modify your do_sampling code by wrapping the sampling loop in an outer loop that sets the sample size. We will want to be able to compare the histograms that are generated for each sample size, so use the subplot command to send each histogram to a different subplot in the same figure (i.e. same window). Write the code for this in the empty cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# this may take a minute to run...\n",
    "pos = 1\n",
    "plt.figure(figsize=(16,6))\n",
    "for sample_size in [2, 5, 10, 20, 40, 100]:\n",
    "    sample_means, sample_vars = do_sampling(female_tigers, sample_size, 10000)\n",
    "    # plot histograms for the means in the top row of plots\n",
    "    ax = plt.subplot(2,6,pos)\n",
    "    ax.hist(sample_means[0,:], 100) \n",
    "    ax.set_xlim(240,280)\n",
    "    # plot histograms for the variances in the botton row of plots\n",
    "    ax = plt.subplot(2,6,pos+6)\n",
    "    ax.hist(sample_vars[0,:], 100) \n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What do you notice about how the distribution of the estimates changes as the sample size increases?\n",
    "\n",
    "## 8. Classifying\n",
    "\n",
    "Compare the histogram of weights of the female and male tigers for the entire population. A simple classifier could choose a threshold weight W and then if a tiger weighs more than W it would label it as male and if it weighs less than W it would label it as female. Looking at the histograms, what would be the best choice for the weight W?\n",
    "\n",
    "Now take a sample of 100 female tigers and 100 male tigers. Plot histograms using these small samples. Looking at the histograms choose a threshold weight again. Is the threshold chosen using the small sample the same as the threshold you chose when using knowledge of the full set of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# plotting all the data\n",
    "ax = plt.subplot(2,1,1)\n",
    "x = ax.hist(female_tigers[0,:], 100, alpha=0.5, label='female') \n",
    "x = ax.hist(male_tigers[0,:], 100, alpha=0.5, label='male')\n",
    "plt.legend(loc='upper right');\n",
    "# Weight of about 275 kg seems to be the best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# plotting samples of 100 from each dataset\n",
    "male_chosen = np.random.choice(male_tigers.shape[1], 100, replace=False)\n",
    "female_chosen = np.random.choice(female_tigers.shape[1], 100, replace=False)\n",
    "ax = plt.subplot(2,1,1)\n",
    "x = ax.hist(female_tigers[0,male_chosen], 100, alpha=0.5, label='female') \n",
    "x = ax.hist(male_tigers[0,female_chosen], 100, alpha=0.5, label='male')\n",
    "plt.legend(loc='upper right');\n",
    "# We can estimate a suitable threshold using the small sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "As we will see later in the tutorial, having insufficient 'training data' can lead to poor choices when designing classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PART 2 – Programming Challenge\n",
    "\n",
    "## 9. Programming exercises\n",
    "\n",
    "For the final stage of the notebook you have four little programming exercises (see end). There are many ways of coding solutions to each of these exercises. Some solutions will be a lot more efficient than others. Learning how to write efficient code is one of the challenges of Python.\n",
    "\n",
    "For each program measure the runtime of your code. You can do this easily by the iPython %timeit command. The command measures the time it takes to execute a single line of code. So to time a block of code you can place the code you want to measure in a simple dummy function called test() and then use %timeit to time how long it takes to execute test(), e.g.\n",
    "\n",
    "    def test():\n",
    "        somecode\n",
    "    \n",
    "    %timeit test()\n",
    "\n",
    "As an example, consider the task of generating and storing 10,000 random numbers. There are three example solutions below. The solutions are functionally equivalent but have different runtimes. Writing efficient code can make a huge difference to execution time.\n",
    "\n",
    "Method 1 - Using a loop and preallocating storage using np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = np.zeros(10000)\n",
    "    for n in range(10000):\n",
    "        x[n] = np.random.uniform(0,1)\n",
    "\n",
    "%timeit test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Method 2 - Using a loop and preallocating unassigned storage using np.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    x=np.empty(10000)\n",
    "    for n in range(10000):\n",
    "        x[n] = np.random.uniform(0,1)\n",
    "\n",
    "%timeit test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Method 3 - Avoiding the loop by asking the numpy.random.uniform function to generate all the numbers in one call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {},
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = np.random.uniform(0,1,10000)\n",
    "\n",
    "%timeit test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows execution times in ms on a Windows machine using Python 3\n",
    "\n",
    "|    | Method 1 | Method 2 | Method 3 |\n",
    "| :- | :-: | :-: | :-: |\n",
    "| Python 3 | 4.46 ms | 4.75 ms | 0.127 ms |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Write solutions to the problems below in any way you please. Measure the execution times of your code for each exercise. \n",
    "\n",
    "1) Consider all the multiplications A times B for integers A and B lying in the range 1 to 1000. How many of these end in the digit 7. (Hint: You may want to experiment with the modulus '%' operator.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Naive approach using for loop\n",
    "def p1_1():\n",
    "    count = 0\n",
    "    for A in range(1,1001):\n",
    "        for B in range(1, 1001):\n",
    "            if (A*B)%10 == 7:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "#print (p1_1())\n",
    "%timeit p1_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def p1_2():\n",
    "    x = np.arange(1,1001)\n",
    "    M = np.outer(x,x) % 10\n",
    "    count = np.sum(M==7)\n",
    "    return count\n",
    "\n",
    "#print (p1_2())\n",
    "%timeit p1_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2) Using the np.random.rand function generate 1,000,000 random numbers in the range 0 to 1 and then find the smallest and largest difference between a pair of adjacent numbers in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# naive approach using a loop\n",
    "def p2_1():\n",
    "    nums = np.random.rand(1000000)\n",
    "    biggest = smallest = np.abs(nums[0]-nums[1])\n",
    "    for i in range(nums.size):\n",
    "        diff = np.abs(nums[i]-nums[i-1])\n",
    "        if diff > biggest:\n",
    "            biggest = diff\n",
    "        elif diff < smallest:\n",
    "            smallest = diff\n",
    "    return smallest, biggest\n",
    "\n",
    "#print (p2_1())\n",
    "%timeit p2_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def p2_2():\n",
    "    nums = np.random.rand(1000000)\n",
    "    diffs = np.diff(nums)\n",
    "    return diffs.min(), diffs.max()\n",
    "\n",
    "#print (p2_2())\n",
    "%timeit p2_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3) Find the integers A and B in the range 1 to 1000 for which A/B lies closest to pi/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# Naive approach using for loop\n",
    "import math\n",
    "def p3_1():\n",
    "    bestA = bestB = 1\n",
    "    biggest = 100\n",
    "    for A in range(1,1001):\n",
    "        for B in range(1, 1001):\n",
    "            diff = abs(float(A)/B - math.pi/4);\n",
    "            if diff < biggest:\n",
    "                biggest = diff\n",
    "                bestA = A\n",
    "                bestB = B\n",
    "    return bestA, bestB\n",
    "\n",
    "#print p3_1()\n",
    "%timeit p3_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def p3_2():\n",
    "    x = np.arange(1,1001)\n",
    "    M = np.abs(np.outer(x, 1.0/x) - math.pi/4)\n",
    "    index = np.argmin(M)\n",
    "    return np.unravel_index(index, M.shape) + np.array([1, 1])\n",
    "\n",
    "#print p3_2()\n",
    "%timeit p3_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4) A random number is selected between 0 and 1 (with a uniform distribution). If a sequence of 4 such numbers is independently generated what is the probability that the sequence will be in ascending order? Estimate the probability by performing the experiment 1,000,000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def p4_1():\n",
    "    ntrials = 1000000\n",
    "    data = np.random.rand(ntrials,4)\n",
    "    diffs = np.diff(data)\n",
    "    is_ascending = np.all(diffs > 0, axis=1)\n",
    "    n_ascending = np.sum(is_ascending)\n",
    "    return float(n_ascending)/ntrials\n",
    "\n",
    "#print p4_1()\n",
    "%timeit p4_1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
